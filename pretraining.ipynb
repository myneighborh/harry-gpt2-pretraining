{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_07 Harry Potter and the Deathly Hallows.txt 1133063 characters\n",
      "cleaned_05 Harry Potter and the Order of the Phoenix.txt 1489734 characters\n",
      "cleaned_02 Harry Potter and the Chamber of Secrets.txt 488771 characters\n",
      "cleaned_06 Harry Potter and the Half-Blood Prince.txt 982041 characters\n",
      "cleaned_03 Harry Potter and the Prisoner of Azkaban.txt 621137 characters\n",
      "cleaned_01 Harry Potter and the Sorcerers Stone.txt 436000 characters\n",
      "cleaned_04 Harry Potter and the Goblet of Fire.txt 1093670 characters\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "def clean_text(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        book_text = file.read()\n",
    "    \n",
    "    cleaned_text = re.sub(r'\\n+', ' ', book_text)\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
    "\n",
    "    filename_only = os.path.basename(filepath)\n",
    "    cleaned_filename = \"cleaned_\" + filename_only\n",
    "\n",
    "    print(cleaned_filename, len(cleaned_text), \"characters\")\n",
    "\n",
    "    folder = os.path.dirname(filepath)\n",
    "    cleaned_path = os.path.join(folder, cleaned_filename)\n",
    "\n",
    "    with open(cleaned_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(cleaned_text)\n",
    "\n",
    "folder_path = \"/Users/hyun/dev_ws/harry_potter/data/\"\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    clean_text(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "글자수: 17 토큰수 4\n",
      "[35376, 318, 2406, 0]\n",
      "Winter is coming!\n",
      "35376\t -> Winter\n",
      "318\t ->  is\n",
      "2406\t ->  coming\n",
      "0\t -> !\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "text = \"Winter is coming!\"\n",
    "\n",
    "tokens = tokenizer.encode(text)\n",
    "\n",
    "print(\"글자수:\", len(text), \"토큰수\", len(tokens))\n",
    "print(tokens)\n",
    "print(tokenizer.decode(tokens))\n",
    "for t in tokens:\n",
    "    print(f\"{t}\\t -> {tokenizer.decode([t])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size : 102400\n",
      "17 10\n",
      "[22247, 2373, 14436, 905, 970, 698, 1145, 657, 1302, 41728]\n",
      "이웃에 방해가 되지 않는 선에서\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer # pip install transformers\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct\")  # KoGPT2 사용\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"skt/kogpt2-base-v2\")  # KoGPT2 사용\n",
    "\n",
    "print(\"Vocab size :\", len(tokenizer))\n",
    "\n",
    "text = \"이웃에 방해가 되지 않는 선에서\"\n",
    "\n",
    "tokens = tokenizer.encode(text)\n",
    "\n",
    "print(len(text), len(tokens))\n",
    "print(tokens)\n",
    "print(tokenizer.decode(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W -> [54] -> W\n",
      "i -> [72] -> i\n",
      "n -> [77] -> n\n",
      "t -> [83] -> t\n",
      "e -> [68] -> e\n",
      "r -> [81] -> r\n",
      "  -> [220] ->  \n",
      "i -> [72] -> i\n",
      "s -> [82] -> s\n",
      "  -> [220] ->  \n",
      "c -> [66] -> c\n",
      "o -> [78] -> o\n",
      "m -> [76] -> m\n",
      "i -> [72] -> i\n",
      "n -> [77] -> n\n",
      "g -> [70] -> g\n",
      "! -> [0] -> !\n"
     ]
    }
   ],
   "source": [
    "for char in text:\n",
    "    token_ids = tokenizer.encode(char)\n",
    "    decoded = tokenizer.decode(token_ids)\n",
    "    print(f\"{char} -> {token_ids} -> {decoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of tokens in txt: 130520\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, txt, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # token_ids = tokenizer.encode(\"<|endoftext|>\" + txt, allowed_special={\"<|endoftext|>\"})\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "\n",
    "        print(\"# of tokens in txt:\", len(token_ids))\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "# with open(\"cleaned_한글문서.txt\", 'r', encoding='utf-8-sig') as file: # 선택: -sig를 붙여서 BOM 제거\n",
    "with open(\"../data/cleaned_02 Harry Potter and the Chamber of Secrets.txt\", 'r', encoding='utf-8-sig') as file: # 선택: -sig를 붙여서 BOM 제거\n",
    "    txt = file.read()\n",
    "\n",
    "dataset = MyDataset(txt, max_length = 32, stride = 4)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=128, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "�s time for you to step aside. This is an Order of Suspension — you’ll find all twelve signatures on it. I’m\n",
      "s time for you to step aside. This is an Order of Suspension — you’ll find all twelve signatures on it. I’m afraid\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "\n",
    "x, y = next(dataiter)\n",
    "\n",
    "print(tokenizer.decode(x[0].tolist()))\n",
    "print(tokenizer.decode(y[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = tokenizer.n_vocab # 50257 Tiktoken\n",
    "#VOCAB_SIZE = len(tokenizer) # AutoTokenizer\n",
    "CONTEXT_LENGTH = 128  # Shortened context length (orig: 1024)\n",
    "EMB_DIM = 768  # Embedding dimension\n",
    "NUM_HEADS = 12  # Number of attention heads\n",
    "NUM_LAYERS = 12  # Number of layers\n",
    "DROP_RATE = 0.1  # Dropout rate\n",
    "QKV_BIAS = False  # Query-key-value bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert d_out % NUM_HEADS == 0, \"d_out must be divisible by n_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.head_dim = d_out // NUM_HEADS\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(DROP_RATE)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(CONTEXT_LENGTH, CONTEXT_LENGTH), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x)  # (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        keys = keys.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
    "        values = values.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
    "\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "\n",
    "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "\n",
    "        return context_vec\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(EMB_DIM, 4 * EMB_DIM),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * EMB_DIM, EMB_DIM),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=EMB_DIM,\n",
    "            d_out=EMB_DIM)\n",
    "    \n",
    "        self.ff = FeedForward()\n",
    "        self.norm1 = LayerNorm(EMB_DIM)\n",
    "        self.norm2 = LayerNorm(EMB_DIM)\n",
    "        self.drop_shortcut = nn.Dropout(DROP_RATE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(VOCAB_SIZE, EMB_DIM)\n",
    "        self.pos_emb = nn.Embedding(CONTEXT_LENGTH, EMB_DIM)\n",
    "        self.drop_emb = nn.Dropout(DROP_RATE)\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock() for _ in range(NUM_LAYERS)])\n",
    "\n",
    "        self.final_norm = LayerNorm(EMB_DIM)\n",
    "        self.out_head = nn.Linear(EMB_DIM, VOCAB_SIZE, bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel()\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens seen: 4096\n",
      "Epoch: 1, Loss: 0.3644899288265724\n",
      "Epoch: 2, Loss: 0.29445035603102737\n",
      "Epoch: 3, Loss: 0.26637565192040497\n",
      "Tokens seen: 4100096\n",
      "Epoch: 4, Loss: 0.2508515864024012\n",
      "Epoch: 5, Loss: 0.24162740882222108\n",
      "Epoch: 6, Loss: 0.23564565621727096\n",
      "Epoch: 7, Loss: 0.23038860240320522\n",
      "Tokens seen: 8196096\n",
      "Epoch: 8, Loss: 0.2255825633843114\n",
      "Epoch: 9, Loss: 0.22118714557388636\n",
      "Epoch: 10, Loss: 0.2186544587997001\n",
      "Epoch: 11, Loss: 0.2148707326002947\n",
      "Tokens seen: 12292096\n",
      "Epoch: 12, Loss: 0.21408080432828017\n",
      "Epoch: 13, Loss: 0.21007435616311126\n",
      "Epoch: 14, Loss: 0.2069803169510496\n",
      "Epoch: 15, Loss: 0.20501594984625268\n",
      "Tokens seen: 16388096\n",
      "Epoch: 16, Loss: 0.2030314862376123\n",
      "Epoch: 17, Loss: 0.2020940687947386\n",
      "Epoch: 18, Loss: 0.2005700552322733\n",
      "Epoch: 19, Loss: 0.19778033668600667\n",
      "Tokens seen: 20484096\n",
      "Epoch: 20, Loss: 0.1960999135543981\n",
      "Epoch: 21, Loss: 0.19552064475816067\n",
      "Epoch: 22, Loss: 0.1935697317592741\n",
      "Epoch: 23, Loss: 0.1923243437461027\n",
      "Tokens seen: 24580096\n",
      "Epoch: 24, Loss: 0.19166415612997972\n",
      "Epoch: 25, Loss: 0.19067846256212925\n",
      "Epoch: 26, Loss: 0.1889052619262943\n",
      "Epoch: 27, Loss: 0.1886303702325333\n",
      "Tokens seen: 28676096\n",
      "Epoch: 28, Loss: 0.18666953816423265\n",
      "Epoch: 29, Loss: 0.18676793581153464\n",
      "Epoch: 30, Loss: 0.18532873373331987\n",
      "Epoch: 31, Loss: 0.18475747941516515\n",
      "Tokens seen: 32772096\n",
      "Epoch: 32, Loss: 0.18438626115951012\n",
      "Epoch: 33, Loss: 0.1839976059052888\n",
      "Epoch: 34, Loss: 0.18301616603229928\n",
      "Epoch: 35, Loss: 0.18206158949164894\n",
      "Tokens seen: 36868096\n",
      "Epoch: 36, Loss: 0.18157319859491558\n",
      "Epoch: 37, Loss: 0.18165110104431317\n",
      "Epoch: 38, Loss: 0.17959471175989766\n",
      "Epoch: 39, Loss: 0.17891828357938708\n",
      "Tokens seen: 40964096\n",
      "Epoch: 40, Loss: 0.17739669286359952\n"
     ]
    }
   ],
   "source": [
    "tokens_seen, global_step = 0, -1\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(40):\n",
    "    model.train()  # Set model to training mode\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for input_batch, target_batch in train_loader:\n",
    "        optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "        input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "        logits = model(input_batch)\n",
    "        loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward() # Calculate loss gradients\n",
    "        optimizer.step() # Update model weights using loss gradients\n",
    "        tokens_seen += input_batch.numel()\n",
    "        global_step += 1\n",
    "\n",
    "        if global_step % 1000 == 0:\n",
    "            print(f\"Tokens seen: {tokens_seen}\")\n",
    "        # Optional evaluation step\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    losses.append(avg_loss)\n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {avg_loss}\")\n",
    "    torch.save(model.state_dict(), \"model_\" + str(epoch + 1).zfill(3) + \".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(128, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파일로 저장했던 네트워크의 가중치들 읽어들이기\n",
    "model.load_state_dict(torch.load(\"model_014.pth\", map_location=device, weights_only=True))\n",
    "model.eval() # dropout을 사용하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.04\t 257\t  a\n",
      "12.34\t 973\t  used\n",
      "11.30\t 991\t  still\n",
      "10.26\t 4084\t  clearly\n",
      "9.36\t 1479\t  free\n",
      "9.21\t 1464\t  always\n",
      "8.99\t 4762\t  believed\n",
      "8.94\t 4978\t  caught\n",
      "8.57\t 284\t  to\n",
      "8.53\t 1908\t  sent\n"
     ]
    }
   ],
   "source": [
    "idx = tokenizer.encode(\"Dobby is\") # 토큰 id의 list\n",
    "idx = torch.tensor(idx).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(idx)\n",
    "\n",
    "logits = logits[:, -1, :]\n",
    "\n",
    "# 가장 확률이 높은 단어 10개 출력\n",
    "top_logits, top_indices = torch.topk(logits, 10) \n",
    "for p, i in zip(top_logits.squeeze(0).tolist(), top_indices.squeeze(0).tolist()):\n",
    "    print(f\"{p:.2f}\\t {i}\\t {tokenizer.decode([i])}\")\n",
    "\n",
    "# 가장 확률이 높은 단어 출력\n",
    "idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "flat = idx_next.squeeze(0) # 배치 차원 제거 torch.Size([1])\n",
    "out = tokenizer.decode(flat.tolist()) # 텐서를 리스트로 바꿔서 디코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : Harry fights and sealed before Harry could stop him, screamed, “ATTACK! ATTACK! ANOTHER ATTACK! NO MORTAL OR GHOST IS SAFE!” The ghoul in the note telling them, which was creeping along the\n",
      "1 : Harry fights and chasing the gateway and Dobby had darted to the bedroom door, pulled it open, and sprinted down the stairs. Mouth dry, stomach lurching, stomach lurching, stomach lurchrolling his stomach lurching, stomach\n",
      "2 : Harry fights. He was difficult: She was a lot bigger than he was. “Dear, dear,” said Lockhart, skittering through the crowd, looking at the crowd, “but she merely came to the crowd backed away,\n",
      "3 : Harry fights and sealed before Harry could stop him, screamed, “ATTACK! ATTACK! ANOTHER ATTACK! NO MORTAL OR GHOST IS SAFE!” There was creeping to the snake skin and splashed onto the note telling\n",
      "4 : Harry fights and modest,” said Mr. Weasley, nodding coldly. “Busy time at the Ministry, I hear,” said Mr. “ Mr. “All right words. “All right outside your dad”\n",
      "5 : Harry fights would clear his throat loudly and become mysteriously deaf until the subject was changed. “An Engorgement Charm, I suppose?” said Hermione, halfway through the ghost?” said Hermione, halfway down a door halfway down agh.\n",
      "6 : Harry fights.” “What’re we doing, Professor?” said Ron, nervously suppressing a burp. “You will be polishing the youngest. You will be polishing the youngest went on the greatest wizard family until the\n",
      "7 : Harry fights. “Dobby will have to punish himself most grievously for coming to see you, sir. Dobby will have to shut his ears in the oven. Dobby will have to come march, sir. Dobby will have to kill you\n",
      "8 : Harry fights and his ridiculous Muggle Protection Act should be scrapped immediately.” Mr. Weasley was unavailable for comment, although his wife told reporters to clear off or she” “What’s a prefect,” said Riddle�\n",
      "9 : Harry fights and Mr. Weasley, then shut himself up in his dormitory. No afternoon ever lasted as long as that one, nor had Gryffindor Tower ever had one, and one of them was alive, and one way clever plan could hear Fang\n"
     ]
    }
   ],
   "source": [
    "start_context = input(\"Start context: \")\n",
    "\n",
    "# idx = tokenizer.encode(start_context, allowed_special={'<|endoftext|>'})\n",
    "idx = tokenizer.encode(start_context)\n",
    "idx = torch.tensor(idx).unsqueeze(0)\n",
    "\n",
    "context_size = model.pos_emb.weight.shape[0] \n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=idx.to(device),\n",
    "        max_new_tokens=50,\n",
    "        context_size= context_size,\n",
    "        top_k=50,\n",
    "        temperature=0.5\n",
    "    )\n",
    "\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    out = tokenizer.decode(flat.tolist()).replace(\"\\n\", \" \")\n",
    "\n",
    "    print(i, \":\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
